{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "\n",
    "# basic input ------------------------------------------------\n",
    " \n",
    "def eq_scripts_load(_sep, _subdir, _file):\n",
    "    \n",
    "    # if specific file selected it should be XLSX one\n",
    "    if _file != \"\":\n",
    "        \n",
    "        if _subdir != '':\n",
    "            _subdir = '/' + _subdir\n",
    "        _subdir = '../../input' + _subdir + '/'\n",
    "\n",
    "        _file = _subdir + _file\n",
    "        \n",
    "        # open excel file\n",
    "        with open(_file, \"rb\") as f:\n",
    "            inmemory_file = io.BytesIO(f.read())\n",
    "        wb = load_workbook(inmemory_file, read_only = True)\n",
    "        \n",
    "        # read data\n",
    "        r = re.compile(r'^(input\\_)*stoich(iometric)*\\_coefficients*$')\n",
    "        st_coeff_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*$')\n",
    "        con_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0], header = 1)\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*$')\n",
    "        type_con = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0]\n",
    "                                 , header = None, nrows = 1).iloc[0,:]\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*k\\_constants\\_log10$')\n",
    "        lg_k_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'heats')\n",
    "        heats_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'targets')\n",
    "        targets = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0], header = None)\n",
    "        \n",
    "        r = re.compile(r'enthalpies')\n",
    "        delta_H = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'^(particle|component)_names*$')\n",
    "        component_name_for_yields = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0]\n",
    "                                                  , header = None).iat[0, 0]\n",
    "        \n",
    "    # use a bunch of plain text files instead\n",
    "    else:\n",
    "          \n",
    "        if _subdir != '':\n",
    "            _subdir = '/' + _subdir\n",
    "        _subdir = '../../input' + _subdir + '/'\n",
    "\n",
    "        file_names = list(os.listdir(path = _subdir))\n",
    "\n",
    "        r = re.compile(r'^(input\\_)*stoich(iometric)*\\_coefficients*')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        st_coeff_data = pd.read_csv(file, sep = _sep)\n",
    "\n",
    "        r = re.compile(r'^(input\\_)*k\\_constants\\_log10')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        lg_k_data = pd.read_csv(file, sep = _sep, decimal = \",\")\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        con_data = pd.read_csv(file, sep = _sep, decimal = \",\", header = 1)\n",
    "        \n",
    "        type_con = pd.read_csv(file, sep = _sep, header = None, nrows = 1).iloc[0,:]\n",
    "        \n",
    "        r = re.compile(r'heats')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        heats_data = pd.read_csv(file, sep = _sep, decimal = \",\")\n",
    "        \n",
    "        r = re.compile(r'targets')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        targets = pd.read_csv(file, sep = _sep, header = None)\n",
    "        \n",
    "        r = re.compile(r'enthalpies')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        delta_H = pd.read_csv(file, sep = _sep)\n",
    "        \n",
    "        r = re.compile(r'^(particle|component)_names*')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        component_name_for_yields = pd.read_csv(file, header = None).iat[0, 0]\n",
    "\n",
    "    return st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H, component_name_for_yields  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# basic preprocessing ----------------------------------------\n",
    "    \n",
    "def eq_preproc(st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H, component_name_for_yields):\n",
    "    \n",
    "    # checking if there are several series\n",
    "    \n",
    "    if 'series' not in con_data.columns:        \n",
    "        con_data['series'], type_con[np.shape(st_coeff_data)[1]] = '', ''\n",
    "    \n",
    "    if 4 not in heats_data.index:\n",
    "        heats_data.loc[4] = ''\n",
    "        print(heats_data)\n",
    "\n",
    "    # series variables\n",
    "    \n",
    "    ser_info = con_data['series'].to_numpy()\n",
    "    ser_unique = np.unique(ser_info)\n",
    "    ser_num = np.shape(np.unique(ser_info))[0]\n",
    "\n",
    "    # matrix of stoich coeff with formal reactions added\n",
    "    st_coeff_matrix = st_coeff_data.drop('name', axis = 1).to_numpy()\n",
    "    formal_matrix = np.eye(np.shape(st_coeff_matrix)[1], dtype = int)\n",
    "    st_coeff_matrix = np.vstack((formal_matrix, st_coeff_matrix))\n",
    "        \n",
    "    # product names lists : full and base components only\n",
    "    \n",
    "    prod_names_con = list(con_data.drop('series', axis = 1))\n",
    "    prod_names = prod_names_con + st_coeff_data['name'].tolist()\n",
    "    \n",
    "    # creating the vector of equilibrium constants including the formal reactions\n",
    "    lg_k = (np.vstack((np.zeros((np.shape(st_coeff_matrix)[1], 1)), lg_k_data.to_numpy().astype(float))))\n",
    "    \n",
    "    # checking the consistency of reagent names in different sheets    \n",
    "    if prod_names_con != list(st_coeff_data.drop('name', axis = 1)):\n",
    "        print('Check the consistency of reagent names!')\n",
    "    \n",
    "    # split concentrations matrix\n",
    "    #con_matrix = [g for _, g in con_data.groupby(['series'])]\n",
    "        \n",
    "    #for cnm_index, cnm in enumerate(con_matrix):\n",
    "        #con_matrix[cnm_index] = cnm.drop('series', axis = 1).to_numpy().astype(float)\n",
    "    con_matrix = con_data.drop('series', axis = 1).to_numpy()\n",
    "    ser_counts = con_data.groupby(['series']).size().tolist();\n",
    "    \n",
    "    # creating vector of indices of components with predetermined concentrations\n",
    "    ign_indices = np.array(type_con.index[type_con == 'eq'])\n",
    "    \n",
    "    # reading volumes from experimental data\n",
    "    volumes = heats_data.drop('data', axis = 1).to_numpy()[0]\n",
    "    \n",
    "    # reading exp heats from experimental data\n",
    "    heats = heats_data.drop('data', axis = 1).to_numpy()[1] - heats_data.drop('data', axis = 1).to_numpy()[2]\n",
    "        \n",
    "    devs = heats_data.drop('data', axis = 1).to_numpy()[3]\n",
    "    \n",
    "    # creating vector of known enthalpies\n",
    "    dH_par = np.hstack((np.zeros(len(prod_names_con)), np.transpose(delta_H.drop('Reaction', axis = 1).to_numpy())[0]))\n",
    "    \n",
    "    # number of constant to find\n",
    "    tar_names = set(targets.to_numpy()[0][1:])\n",
    "    tar_num = [index for index, item in enumerate(prod_names) if item in tar_names]\n",
    "    \n",
    "    # number of enthalpy to find\n",
    "    dH_names = np.hstack((prod_names_con, np.transpose(delta_H.drop('Value', axis = 1).to_numpy())[0]))\n",
    "    un_el = set(prod_names) - set(dH_names)\n",
    "    dH_ind_wtf = list([index for index, item in enumerate(prod_names) if item in un_el])\n",
    "    un_el = set(prod_names) - (set(prod_names) - set(dH_names))\n",
    "    dH_ind = list([index for index, item in enumerate(prod_names) if item in un_el])\n",
    "    \n",
    "    if component_name_for_yields not in prod_names:\n",
    "        print('The component name for partition should be among those of basis components')\n",
    "        \n",
    "    idx, = np.where(component_name_for_yields == np.array(prod_names_con))\n",
    "    \n",
    "    return ser_num, st_coeff_matrix, prod_names, lg_k, prod_names_con, con_matrix, ign_indices, ser_counts, ser_info, type_con, volumes, heats, devs, tar_num, dH_ind, dH_ind_wtf, dH_par, idx  \n",
    "    # ser_num, ser_counts, ser_info not further used yet! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "def eq_calc(max_iter, eps, ser_num, st_coeff_matrix, type_con, lg_k,\n",
    "            con_matrix, ign_indices, ser_counts, ser_info): # ser_num, ser_counts, ser_info not further used yet!\n",
    "    \n",
    "    c_res_out = [0] * len(con_matrix)\n",
    "    \n",
    "    for k in range(np.shape(con_matrix)[0]):\n",
    "                \n",
    "        reag_eq_con_matrix = deepcopy(con_matrix[k]) # initial estimation of equilibrium concentrations of reagents\n",
    "        init_conc = deepcopy(con_matrix[k]) # value for residual calculation in inner function\n",
    "        \n",
    "        prod_eq_con_matrix = inner_eq_calc(reag_eq_con_matrix, max_iter, lg_k, st_coeff_matrix, init_conc, ign_indices, eps)   \n",
    "                    \n",
    "        c_res_out[k] += prod_eq_con_matrix[0]\n",
    "\n",
    "    return c_res_out\n",
    "\n",
    "def inner_eq_calc(reag_eq_con_matrix, max_iter, lg_k, st_coeff_matrix, init_conc, ign_indices, eps): \n",
    "    \n",
    "    lg_k, st_coeff_matrix, con_matrix = deepcopy(lg_k), deepcopy(st_coeff_matrix), deepcopy(init_conc)\n",
    "    \n",
    "    # if some equilibrium concentrations are set\n",
    "    if np.shape(ign_indices)[0] > 0:\n",
    "\n",
    "        range_start = st_coeff_matrix.shape[1]\n",
    "        range_end = lg_k.shape[0]\n",
    "        \n",
    "        lg_k_upd = np.matmul(st_coeff_matrix[range_start:range_end, ign_indices],\n",
    "          np.log10(init_conc[ign_indices])) #+ lg_k[range_start:range_end]\n",
    "        \n",
    "        lg_k[range_start:range_end] = lg_k_upd.reshape(-1, 1) + lg_k[range_start:range_end]\n",
    "        \n",
    "        init_conc = np.delete(init_conc, ign_indices, axis = 0)\n",
    "        reag_eq_con_matrix = np.delete(reag_eq_con_matrix, ign_indices, axis = 0)\n",
    "        st_coeff_matrix = np.delete(st_coeff_matrix, ign_indices, axis = 1)\n",
    "\n",
    "    # start of iterative procedure\n",
    "    for it in range(max_iter):\n",
    "\n",
    "        # caclulating the equilibrium concentrations of products\n",
    "        prod_eq_con_matrix = np.exp(np.transpose(np.array(math.log(10) * np.array(lg_k))) +\n",
    "                                    np.dot(st_coeff_matrix, np.log(reag_eq_con_matrix)))\n",
    "            \n",
    "        # calculating the total concentrations of reagents\n",
    "        reag_tot_con_matrix_calc = np.transpose(np.dot(np.transpose(st_coeff_matrix), np.transpose(prod_eq_con_matrix)))\n",
    "            \n",
    "        # calculating the residuals\n",
    "        g_res = np.array(reag_tot_con_matrix_calc) - np.array(init_conc)\n",
    "                            \n",
    "        # calculating the Jacobi matrices\n",
    "        jac_matrix = np.dot(np.transpose(st_coeff_matrix), (np.array(st_coeff_matrix) * np.transpose(prod_eq_con_matrix)))   \n",
    "        \n",
    "        # new estimation of equilibrium concentrations of reagents\n",
    "        prev = np.log(reag_eq_con_matrix)\n",
    "        reag_eq_con_matrix = np.exp(prev - np.transpose(np.dot(np.linalg.inv(jac_matrix), np.transpose(g_res))))\n",
    "        reag_eq_con_matrix = reag_eq_con_matrix[0]\n",
    "        error = abs(np.log(reag_eq_con_matrix) - prev)\n",
    "                \n",
    "        # checking the convergence\n",
    "        if np.max(error) < eps:\n",
    "               \n",
    "            # if some equilibrium concentrations are set\n",
    "            if np.shape(ign_indices)[0] > 0:\n",
    "                prod_eq_con_matrix[:, ign_indices] = con_matrix[ign_indices]\n",
    "                        \n",
    "            break\n",
    "\n",
    "    return prod_eq_con_matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          data      1           2           3           4            5  \\\n",
      "0      volumes     15      15.025       15.05      15.075         15.1   \n",
      "1  observation      0    0.069951    0.069513    0.069854     0.071474   \n",
      "2     dilution      0 -0.00195354  0.00247103 -0.00017689  0.000556654   \n",
      "3    deviation  1e-06       1e-06       1e-06       1e-06        1e-06   \n",
      "4                                                                        \n",
      "\n",
      "            6           7           8            9          10           11  \\\n",
      "0      15.125       15.15      15.175         15.2      15.225        15.25   \n",
      "1    0.067108    0.066289    0.056026     0.044493    0.027882     0.009239   \n",
      "2  0.00070773  0.00185424  0.00108107  0.000473122  0.00106313  0.000271799   \n",
      "3       1e-06       1e-06       1e-06        1e-06       1e-06        1e-06   \n",
      "4                                                                             \n",
      "\n",
      "           12           13           14          15           16  \n",
      "0      15.275         15.3       15.325       15.35       15.375  \n",
      "1    0.003057     0.002486     0.000906       4e-05    -0.001894  \n",
      "2  0.00116842  0.000232129  0.000917353  0.00126996 -0.000397241  \n",
      "3       1e-06        1e-06        1e-06       1e-06        1e-06  \n",
      "4                                                                 \n",
      "\n",
      "Stoich coeff data\n",
      "   PLP  T3H  name\n",
      "0    1    1  Comp\n",
      "\n",
      "lg K\n",
      "   lg_k\n",
      "0  5.13\n",
      "\n",
      "concentrations\n",
      "         PLP           T3H series\n",
      "0   0.000797  1.000000e-18       \n",
      "1   0.000796  9.912290e-05       \n",
      "2   0.000794  1.979165e-04       \n",
      "3   0.000793  2.963825e-04       \n",
      "4   0.000792  3.945225e-04       \n",
      "5   0.000790  4.923381e-04       \n",
      "6   0.000789  5.898309e-04       \n",
      "7   0.000788  6.870025e-04       \n",
      "8   0.000787  7.838545e-04       \n",
      "9   0.000785  8.803885e-04       \n",
      "10  0.000784  9.766060e-04       \n",
      "11  0.000783  1.072509e-03       \n",
      "12  0.000781  1.168098e-03       \n",
      "13  0.000780  1.263375e-03       \n",
      "14  0.000779  1.358342e-03       \n",
      "15  0.000778  1.453001e-03       \n",
      "\n",
      "type con\n",
      "0    tot\n",
      "1    tot\n",
      "3       \n",
      "Name: 0, dtype: object\n",
      "\n",
      "experimental data\n",
      "          data      1           2           3           4            5  \\\n",
      "0      volumes     15      15.025       15.05      15.075         15.1   \n",
      "1  observation      0    0.069951    0.069513    0.069854     0.071474   \n",
      "2     dilution      0 -0.00195354  0.00247103 -0.00017689  0.000556654   \n",
      "3    deviation  1e-06       1e-06       1e-06       1e-06        1e-06   \n",
      "4                                                                        \n",
      "\n",
      "            6           7           8            9          10           11  \\\n",
      "0      15.125       15.15      15.175         15.2      15.225        15.25   \n",
      "1    0.067108    0.066289    0.056026     0.044493    0.027882     0.009239   \n",
      "2  0.00070773  0.00185424  0.00108107  0.000473122  0.00106313  0.000271799   \n",
      "3       1e-06       1e-06       1e-06        1e-06       1e-06        1e-06   \n",
      "4                                                                             \n",
      "\n",
      "           12           13           14          15           16  \n",
      "0      15.275         15.3       15.325       15.35       15.375  \n",
      "1    0.003057     0.002486     0.000906       4e-05    -0.001894  \n",
      "2  0.00116842  0.000232129  0.000917353  0.00126996 -0.000397241  \n",
      "3       1e-06        1e-06        1e-06       1e-06        1e-06  \n",
      "4                                                                 \n",
      "\n",
      "targets\n",
      "            0     1\n",
      "0  constants   Comp\n",
      "\n",
      "delta_H\n",
      "Empty DataFrame\n",
      "Columns: [Reaction, Value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# input for xlsx file\n",
    "_subdir = \"calorimetry\"\n",
    "_sep = \";\"\n",
    "_file = \"test_1.xlsx\"\n",
    "\n",
    "max_iter, eps = 1000, 0.0000001\n",
    "\n",
    "st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H, component_name_for_yields = eq_scripts_load(_sep, _subdir, _file)\n",
    "\n",
    "(ser_num, st_coeff_matrix, prod_names, lg_k, prod_names_con, con_matrix, ign_indices, ser_counts,\n",
    " ser_info, type_con, volumes, heats, devs, tar_num, dH_ind, dH_ind_wtf, dH_par, idx) = eq_preproc(st_coeff_data,\n",
    "                                                                                             lg_k_data, con_data, type_con,\n",
    "                                                                                             heats_data, targets, delta_H, component_name_for_yields)\n",
    "\n",
    "c_res_out = eq_calc(max_iter, eps, ser_num, st_coeff_matrix, type_con, lg_k,\n",
    "            con_matrix, ign_indices, ser_counts, ser_info)\n",
    "\n",
    "print('\\nStoich coeff data')\n",
    "print(st_coeff_data)\n",
    "\n",
    "print('\\nlg K')\n",
    "print(lg_k_data)\n",
    "\n",
    "print('\\nconcentrations')\n",
    "print(con_data)\n",
    "\n",
    "print('\\ntype con')\n",
    "print(type_con)\n",
    "\n",
    "print('\\nexperimental data')\n",
    "print(heats_data)\n",
    "\n",
    "print('\\ntargets')\n",
    "print(targets)\n",
    "\n",
    "print('\\ndelta_H')\n",
    "print(delta_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series\n",
      "1\n",
      "[16]\n",
      "['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '']\n",
      "\n",
      "St coeff matr\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [1 1]]\n",
      "\n",
      "prod names\n",
      "['PLP', 'T3H', 'Comp']\n",
      "['PLP', 'T3H']\n",
      "\n",
      "const\n",
      "[[0.  ]\n",
      " [0.  ]\n",
      " [5.13]]\n",
      "\n",
      "concentrations\n",
      "[[7.97022000e-04 1.00000000e-18]\n",
      " [7.95695999e-04 9.91228990e-05]\n",
      " [7.94374403e-04 1.97916525e-04]\n",
      " [7.93057190e-04 2.96382517e-04]\n",
      " [7.91744338e-04 3.94522502e-04]\n",
      " [7.90435825e-04 4.92338095e-04]\n",
      " [7.89131631e-04 5.89830903e-04]\n",
      " [7.87831733e-04 6.87002520e-04]\n",
      " [7.86536110e-04 7.83854532e-04]\n",
      " [7.85244742e-04 8.80388513e-04]\n",
      " [7.83957608e-04 9.76606026e-04]\n",
      " [7.82674686e-04 1.07250863e-03]\n",
      " [7.81395956e-04 1.16809785e-03]\n",
      " [7.80121398e-04 1.26337525e-03]\n",
      " [7.78850991e-04 1.35834233e-03]\n",
      " [7.77584715e-04 1.45300060e-03]]\n",
      "[]\n",
      "\n",
      "type con\n",
      "0    tot\n",
      "1    tot\n",
      "3       \n",
      "Name: 0, dtype: object\n",
      "\n",
      "volumes\n",
      "[15.0 15.024997 15.049994 15.074991 15.099988 15.124985 15.149982\n",
      " 15.174979 15.199976 15.224973 15.24997 15.274967 15.299964 15.324961\n",
      " 15.349958 15.374955]\n",
      "\n",
      "heats\n",
      "[0.0 0.071904538 0.067041971 0.07003089 0.07091734599999999 0.06640027\n",
      " 0.064434764 0.054944928 0.044019878 0.02681887 0.008967201000000001\n",
      " 0.0018885769999999998 0.0022538709999999997 -1.135299999999997e-05\n",
      " -0.001229958 -0.001496759]\n",
      "\n",
      "deviations\n",
      "[1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06 1e-06\n",
      " 1e-06 1e-06 1e-06 1e-06]\n",
      "\n",
      "what to find and what is known\n",
      "[2]\n",
      "[0, 1]\n",
      "[2]\n",
      "\n",
      "enthalpies\n",
      "[0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "print('\\nSeries')\n",
    "print(ser_num)\n",
    "print(ser_counts)\n",
    "print(ser_info)\n",
    "\n",
    "print('\\nSt coeff matr')\n",
    "print(st_coeff_matrix)\n",
    "\n",
    "print('\\nprod names')\n",
    "print(prod_names)\n",
    "print(prod_names_con)\n",
    "\n",
    "print('\\nconst')\n",
    "print(lg_k)\n",
    "\n",
    "print('\\nconcentrations')\n",
    "print(con_matrix)\n",
    "\n",
    "print(ign_indices)\n",
    "\n",
    "print('\\ntype con')\n",
    "print(type_con)\n",
    "\n",
    "print('\\nvolumes')\n",
    "print(volumes)\n",
    "\n",
    "print('\\nheats')\n",
    "print(heats)\n",
    "\n",
    "print('\\ndeviations')\n",
    "print(devs)\n",
    "\n",
    "print('\\nwhat to find and what is known')\n",
    "print(tar_num)\n",
    "print(dH_ind)\n",
    "print(dH_ind_wtf)\n",
    "\n",
    "print('\\nenthalpies')\n",
    "print(dH_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eq conc\n",
      "[[7.97022000e-04 9.21528957e-21 9.90784710e-19]\n",
      " [6.97615339e-04 1.04223909e-06 9.80806599e-05]\n",
      " [5.98877798e-04 2.41992000e-06 1.95496605e-04]\n",
      " [5.00996218e-04 4.32154539e-06 2.92060972e-04]\n",
      " [4.04324982e-04 7.10314595e-06 3.87419356e-04]\n",
      " [3.09610296e-04 1.15125657e-05 4.80825529e-04]\n",
      " [2.18643156e-04 1.93424280e-05 5.70488475e-04]\n",
      " [1.36273225e-04 3.54440128e-05 6.51558508e-04]\n",
      " [7.40297191e-05 7.13481412e-05 7.12506391e-04]\n",
      " [4.06485875e-05 1.35792358e-04 7.44596155e-04]\n",
      " [2.57377216e-05 2.18386140e-04 7.58219886e-04]\n",
      " [1.83824627e-05 3.08216402e-04 7.64292223e-04]\n",
      " [1.41869711e-05 4.00888869e-04 7.67208985e-04]\n",
      " [1.15159629e-05 4.94769811e-04 7.68605436e-04]\n",
      " [9.67796265e-06 5.89169297e-04 7.69173031e-04]\n",
      " [8.33995108e-06 6.83755840e-04 7.69244770e-04]]\n",
      "(16, 3)\n"
     ]
    }
   ],
   "source": [
    "print('\\nEq conc')\n",
    "print(np.array(c_res_out))\n",
    "print(np.shape(c_res_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.024997 15.049994 15.074991 15.099988 15.124985 15.149982 15.174979\n",
      " 15.199976 15.224973 15.24997  15.274967 15.299964 15.324961 15.349958\n",
      " 15.374955]\n",
      "[47.57917279]\n"
     ]
    }
   ],
   "source": [
    "dif_conc, devi, d_heats, dV, con_matrix_red = [], [], [], [], [] \n",
    "\n",
    "# finding the increment in equilibrium concentrations of products - needed for dH calculation\n",
    "\n",
    "for s in range(ser_num):\n",
    "    \n",
    "    for k in range(ser_counts[s] - 1):\n",
    "        \n",
    "        dif_conc.append(c_res_out[int(np.sum(ser_counts[:s])) + k + 1] - c_res_out[int(np.sum(ser_counts[:s])) + k])\n",
    "\n",
    "        devi.append(devs[int(np.sum(ser_counts[:s])) + k + 1])\n",
    "        \n",
    "        d_heats.append(heats[int(np.sum(ser_counts[:s])) + k + 1])\n",
    "        \n",
    "        #dV.append(volumes[int(np.sum(ser_counts[:s])) + k + 1] - volumes[int(np.sum(ser_counts[:s])) + k])\n",
    "        \n",
    "        con_matrix_red.append(con_matrix[int(np.sum(ser_counts[:s])) + k + 1])\n",
    "\n",
    "# transforming deviation to the matrix form\n",
    "devs = np.diag((1 / (np.array(devi) * np.array(devi))) * (np.sum(np.array(devi) * np.array(devi)) / len(devi))) \n",
    "dV = volumes[1:] # which one of lists of volumes should be used - the differences or the total ones - \n",
    "                # depends on the type of calorimeter! Just freaking amazing!\n",
    "                # Got an idea how to fix it later on. Gotta check if volumes in the initial data, \n",
    "                # if no, the vector containing 1 should be created instead\n",
    "\n",
    "dif_conc, d_heats, dV, con_matrix_red = np.array(dif_conc), np.array(d_heats), np.array(dV).astype(float), np.array(con_matrix_red)\n",
    "\n",
    "print(dV)\n",
    "# finding vector of experimental values\n",
    "\n",
    "q_corr = d_heats\n",
    "for i in range(len(d_heats)):\n",
    "    for j in range(len(dV[dH_ind])):\n",
    "        q_corr[i] -= dV[dH_ind[j]]*dif_conc[i, dH_ind[j]]*dH_par[j]\n",
    "\n",
    "A = dV[dH_ind_wtf] * dif_conc[:, dH_ind_wtf] #/ con_matrix_red[:, idx]\n",
    "AT = np.transpose(A)\n",
    "LTP = np.linalg.inv(np.dot(np.dot(AT, devs), A))\n",
    "RTP = np.dot(np.dot(AT, devs), q_corr)\n",
    "dH_res = np.dot(LTP, RTP)\n",
    "print(dH_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
