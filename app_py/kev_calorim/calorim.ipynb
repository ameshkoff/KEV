{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "\n",
    "# basic input ------------------------------------------------\n",
    " \n",
    "def eq_scripts_load(_sep, _subdir, _file):\n",
    "    \n",
    "    # if specific file selected it should be XLSX one\n",
    "    if _file != \"\":\n",
    "        \n",
    "        if _subdir != '':\n",
    "            _subdir = '/' + _subdir\n",
    "        _subdir = '../../input' + _subdir + '/'\n",
    "\n",
    "        _file = _subdir + _file\n",
    "        \n",
    "        # open excel file\n",
    "        with open(_file, \"rb\") as f:\n",
    "            inmemory_file = io.BytesIO(f.read())\n",
    "        wb = load_workbook(inmemory_file, read_only = True)\n",
    "        \n",
    "        # read data\n",
    "        r = re.compile(r'^(input\\_)*stoich(iometric)*\\_coefficients*$')\n",
    "        st_coeff_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*$')\n",
    "        con_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0], header = 1)\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*$')\n",
    "        type_con = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0]\n",
    "                                 , header = None, nrows = 1).iloc[0,:]\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*k\\_constants\\_log10$')\n",
    "        lg_k_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'heats')\n",
    "        heats_data = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "        r = re.compile(r'targets')\n",
    "        targets = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0], header = None)\n",
    "        \n",
    "        r = re.compile(r'enthalpies')\n",
    "        delta_H = pd.read_excel(_file, sheet_name = list(filter(r.search, wb.sheetnames))[0])\n",
    "        \n",
    "    # use a bunch of plain text files instead\n",
    "    else:\n",
    "          \n",
    "        if _subdir != '':\n",
    "            _subdir = '/' + _subdir\n",
    "        _subdir = '../../input' + _subdir + '/'\n",
    "\n",
    "        file_names = list(os.listdir(path = _subdir))\n",
    "\n",
    "        r = re.compile(r'^(input\\_)*stoich(iometric)*\\_coefficients*')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        st_coeff_data = pd.read_csv(file, sep = _sep)\n",
    "\n",
    "        r = re.compile(r'^(input\\_)*k\\_constants\\_log10')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        lg_k_data = pd.read_csv(file, sep = _sep, decimal = \",\")\n",
    "        \n",
    "        r = re.compile(r'^(input\\_)*concentrations*')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        con_data = pd.read_csv(file, sep = _sep, decimal = \",\", header = 1)\n",
    "        \n",
    "        type_con = pd.read_csv(file, sep = _sep, header = None, nrows = 1).iloc[0,:]\n",
    "        \n",
    "        r = re.compile(r'heats')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        heats_data = pd.read_csv(file, sep = _sep, decimal = \",\")\n",
    "        \n",
    "        r = re.compile(r'targets')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        targets = pd.read_csv(file, sep = _sep, header = None)\n",
    "        \n",
    "        r = re.compile(r'enthalpies')\n",
    "        file = list(filter(r.search, file_names))[0]\n",
    "        file = _subdir + str(file)\n",
    "        delta_H = pd.read_csv(file, sep = _sep)\n",
    "\n",
    "    return st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# basic preprocessing ----------------------------------------\n",
    "    \n",
    "def eq_preproc(st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H):\n",
    "    \n",
    "    # checking if there are several series\n",
    "    \n",
    "    if 'series' not in con_data.columns:        \n",
    "        con_data['series'], type_con[np.shape(st_coeff_data)[1]] = '', ''\n",
    "    \n",
    "    if 4 not in heats_data.index:\n",
    "        heats_data.loc[4] = ''\n",
    "        print(heats_data)\n",
    "\n",
    "    # series variables\n",
    "    \n",
    "    ser_info = con_data['series'].to_numpy()\n",
    "    ser_unique = np.unique(ser_info)\n",
    "    ser_num = np.shape(np.unique(ser_info))[0]\n",
    "\n",
    "    # matrix of stoich coeff with formal reactions added\n",
    "    st_coeff_matrix = st_coeff_data.drop('name', axis = 1).to_numpy()\n",
    "    formal_matrix = np.eye(np.shape(st_coeff_matrix)[1], dtype = int)\n",
    "    st_coeff_matrix = np.vstack((formal_matrix, st_coeff_matrix))\n",
    "        \n",
    "    # product names lists : full and base components only\n",
    "    \n",
    "    prod_names_con = list(con_data.drop('series', axis = 1))\n",
    "    prod_names = prod_names_con + st_coeff_data['name'].tolist()\n",
    "    \n",
    "    # creating the vector of equilibrium constants including the formal reactions\n",
    "    lg_k = (np.vstack((np.zeros((np.shape(st_coeff_matrix)[1], 1)), lg_k_data.to_numpy().astype(float))))\n",
    "    \n",
    "    # checking the consistency of reagent names in different sheets    \n",
    "    if prod_names_con != list(st_coeff_data.drop('name', axis = 1)):\n",
    "        print('Check the consistency of reagent names!')\n",
    "    \n",
    "    # split concentrations matrix\n",
    "    #con_matrix = [g for _, g in con_data.groupby(['series'])]\n",
    "        \n",
    "    #for cnm_index, cnm in enumerate(con_matrix):\n",
    "        #con_matrix[cnm_index] = cnm.drop('series', axis = 1).to_numpy().astype(float)\n",
    "    con_matrix = con_data.drop('series', axis = 1).to_numpy()\n",
    "    ser_counts = con_data.groupby(['series']).size().tolist();\n",
    "    \n",
    "    # creating vector of indices of components with predetermined concentrations\n",
    "    ign_indices = np.array(type_con.index[type_con == 'eq'])\n",
    "    \n",
    "    # reading volumes from experimental data\n",
    "    volumes = heats_data.drop('data', axis = 1).to_numpy()[0]\n",
    "    \n",
    "    # reading exp heats from experimental data\n",
    "    heats = heats_data.drop('data', axis = 1).to_numpy()[1] - heats_data.drop('data', axis = 1).to_numpy()[2]\n",
    "        \n",
    "    devs = heats_data.drop('data', axis = 1).to_numpy()[3]\n",
    "    \n",
    "    # number of constant to find\n",
    "    tar_names = set(targets.to_numpy()[0][1:])\n",
    "    tar_num = [index for index, item in enumerate(prod_names) if item in tar_names]\n",
    "    \n",
    "    # number of enthalpy to find\n",
    "    dH_names = np.hstack((prod_names_con, np.transpose(delta_H.drop('Value', axis = 1).to_numpy())[0]))\n",
    "    un_el = set(prod_names) - set(dH_names)\n",
    "    dH_ind = [index for index, item in enumerate(prod_names) if item in un_el]\n",
    "    \n",
    "    return ser_num, st_coeff_matrix, prod_names, lg_k, prod_names_con, con_matrix, ign_indices, ser_counts, ser_info, type_con, volumes, heats, devs, tar_num, dH_ind  \n",
    "    # ser_num, ser_counts, ser_info not further used yet! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################## #\n",
    "#                                                            #\n",
    "# Name: KEV:Constant Evaluator                               #\n",
    "# Author: GGamov                                             #\n",
    "# Date: 2019                                                 #\n",
    "#                                                            #\n",
    "# ########################################################## #\n",
    "\n",
    "# import libraries -------------------------------------------\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "def eq_calc(max_iter, eps, ser_num, st_coeff_matrix, type_con, lg_k,\n",
    "            con_matrix, ign_indices, ser_counts, ser_info): # ser_num, ser_counts, ser_info not further used yet!\n",
    "    \n",
    "    c_res_out = [0] * len(con_matrix)\n",
    "    \n",
    "    for k in range(np.shape(con_matrix)[0]):\n",
    "                \n",
    "        reag_eq_con_matrix = deepcopy(con_matrix[k]) # initial estimation of equilibrium concentrations of reagents\n",
    "        init_conc = deepcopy(con_matrix[k]) # value for residual calculation in inner function\n",
    "        \n",
    "        prod_eq_con_matrix = inner_eq_calc(reag_eq_con_matrix, max_iter, lg_k, st_coeff_matrix, init_conc, ign_indices, eps)   \n",
    "                    \n",
    "        c_res_out[k] += prod_eq_con_matrix[0]\n",
    "\n",
    "    return c_res_out\n",
    "\n",
    "def inner_eq_calc(reag_eq_con_matrix, max_iter, lg_k, st_coeff_matrix, init_conc, ign_indices, eps): \n",
    "    \n",
    "    lg_k, st_coeff_matrix, con_matrix = deepcopy(lg_k), deepcopy(st_coeff_matrix), deepcopy(init_conc)\n",
    "    \n",
    "    # if some equilibrium concentrations are set\n",
    "    if np.shape(ign_indices)[0] > 0:\n",
    "\n",
    "        range_start = st_coeff_matrix.shape[1]\n",
    "        range_end = lg_k.shape[0]\n",
    "        \n",
    "        lg_k_upd = np.matmul(st_coeff_matrix[range_start:range_end, ign_indices],\n",
    "          np.log10(init_conc[ign_indices])) #+ lg_k[range_start:range_end]\n",
    "        \n",
    "        lg_k[range_start:range_end] = lg_k_upd.reshape(-1, 1) + lg_k[range_start:range_end]\n",
    "        \n",
    "        init_conc = np.delete(init_conc, ign_indices, axis = 0)\n",
    "        reag_eq_con_matrix = np.delete(reag_eq_con_matrix, ign_indices, axis = 0)\n",
    "        st_coeff_matrix = np.delete(st_coeff_matrix, ign_indices, axis = 1)\n",
    "\n",
    "    # start of iterative procedure\n",
    "    for it in range(max_iter):\n",
    "\n",
    "        # caclulating the equilibrium concentrations of products\n",
    "        prod_eq_con_matrix = np.exp(np.transpose(np.array(math.log(10) * np.array(lg_k))) +\n",
    "                                    np.dot(st_coeff_matrix, np.log(reag_eq_con_matrix)))\n",
    "            \n",
    "        # calculating the total concentrations of reagents\n",
    "        reag_tot_con_matrix_calc = np.transpose(np.dot(np.transpose(st_coeff_matrix), np.transpose(prod_eq_con_matrix)))\n",
    "            \n",
    "        # calculating the residuals\n",
    "        g_res = np.array(reag_tot_con_matrix_calc) - np.array(init_conc)\n",
    "                            \n",
    "        # calculating the Jacobi matrices\n",
    "        jac_matrix = np.dot(np.transpose(st_coeff_matrix), (np.array(st_coeff_matrix) * np.transpose(prod_eq_con_matrix)))   \n",
    "        \n",
    "        # new estimation of equilibrium concentrations of reagents\n",
    "        prev = np.log(reag_eq_con_matrix)\n",
    "        reag_eq_con_matrix = np.exp(prev - np.transpose(np.dot(np.linalg.inv(jac_matrix), np.transpose(g_res))))\n",
    "        reag_eq_con_matrix = reag_eq_con_matrix[0]\n",
    "        error = abs(np.log(reag_eq_con_matrix) - prev)\n",
    "                \n",
    "        # checking the convergence\n",
    "        if np.max(error) < eps:\n",
    "               \n",
    "            # if some equilibrium concentrations are set\n",
    "            if np.shape(ign_indices)[0] > 0:\n",
    "                prod_eq_con_matrix[:, ign_indices] = con_matrix[ign_indices]\n",
    "                        \n",
    "            break\n",
    "\n",
    "    return prod_eq_con_matrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stoich coeff data\n",
      "   H  L  M name\n",
      "0  1  1  0   HL\n",
      "1  2  1  0  H2L\n",
      "2  0  1  1   ML\n",
      "3  1  1  1  HML\n",
      "\n",
      "lg K\n",
      "   lg_k\n",
      "0  5.35\n",
      "1  7.34\n",
      "2  7.44\n",
      "3  9.47\n",
      "\n",
      "concentrations\n",
      "           H             L        M series\n",
      "0   0.019110  1.000000e-15  0.01486      a\n",
      "1   0.019650  4.205000e-03  0.01451      a\n",
      "2   0.019110  1.000000e-15  0.01486      b\n",
      "3   0.019650  4.172000e-03  0.01451      b\n",
      "4   0.019110  1.000000e-15  0.01486      c\n",
      "5   0.019650  4.173000e-03  0.01451      c\n",
      "6   0.019110  1.000000e-15  0.01486      d\n",
      "7   0.019650  4.191000e-03  0.01451      d\n",
      "8   0.002568  1.000000e-15  0.01486      e\n",
      "9   0.003495  4.183000e-03  0.01451      e\n",
      "10  0.002568  1.000000e-15  0.01486      f\n",
      "11  0.003492  4.171000e-03  0.01451      f\n",
      "12  0.002568  1.000000e-15  0.01486      g\n",
      "13  0.003494  4.179000e-03  0.01451      g\n",
      "14  0.002568  1.000000e-15  0.01486      h\n",
      "15  0.003495  4.182000e-03  0.01451      h\n",
      "\n",
      "type con\n",
      "0    tot\n",
      "1    tot\n",
      "2    tot\n",
      "3    NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "experimental data\n",
      "          data    1        2    3        4    5        6    7        8    9  \\\n",
      "0      volumes    1        2    1        2    1        2    1        2    1   \n",
      "1  observation    0 -10.0952    0 -10.4137    0 -10.8359    0 -10.7336    0   \n",
      "2     dilution    0        0    0        0    0        0    0        0    0   \n",
      "3    deviation  0.1      0.1  0.1      0.1  0.1      0.1  0.1      0.1  0.1   \n",
      "4       series    a        a    b        b    c        c    d        d    e   \n",
      "\n",
      "      10   11      12   13      14   15      16  \n",
      "0      2    1       2    1       2    1       2  \n",
      "1 -9.776    0 -9.9857    0 -9.7711    0 -9.8545  \n",
      "2      0    0       0    0       0    0       0  \n",
      "3    0.1  0.1     0.1  0.1     0.1  0.1     0.1  \n",
      "4      e    f       f    g       g    h       h  \n",
      "\n",
      "targets\n",
      "            0\n",
      "0  constants \n",
      "\n",
      "delta_H\n",
      "  Reaction  Value\n",
      "0       HL  -5.18\n",
      "1      H2L  -2.96\n"
     ]
    }
   ],
   "source": [
    "# input for xlsx file\n",
    "_subdir = \"calorimetry\"\n",
    "_sep = \";\"\n",
    "_file = \"test_3.xlsx\"\n",
    "\n",
    "max_iter, eps = 1000, 0.0000001\n",
    "\n",
    "st_coeff_data, lg_k_data, con_data, type_con, heats_data, targets, delta_H = eq_scripts_load(_sep, _subdir, _file)\n",
    "\n",
    "(ser_num, st_coeff_matrix, prod_names, lg_k, prod_names_con, con_matrix, ign_indices, ser_counts,\n",
    " ser_info, type_con, volumes, heats, devs, tar_num, dH_ind) = eq_preproc(st_coeff_data, lg_k_data, con_data, type_con, heats_data, \n",
    "                                                   targets, delta_H)\n",
    "\n",
    "c_res_out = eq_calc(max_iter, eps, ser_num, st_coeff_matrix, type_con, lg_k,\n",
    "            con_matrix, ign_indices, ser_counts, ser_info)\n",
    "\n",
    "print('\\nStoich coeff data')\n",
    "print(st_coeff_data)\n",
    "\n",
    "print('\\nlg K')\n",
    "print(lg_k_data)\n",
    "\n",
    "print('\\nconcentrations')\n",
    "print(con_data)\n",
    "\n",
    "print('\\ntype con')\n",
    "print(type_con)\n",
    "\n",
    "print('\\nexperimental data')\n",
    "print(heats_data)\n",
    "\n",
    "print('\\ntargets')\n",
    "print(targets)\n",
    "\n",
    "print('\\ndelta_H')\n",
    "print(delta_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Series\n",
      "8\n",
      "[2, 2, 2, 2, 2, 2, 2, 2]\n",
      "['a' 'a' 'b' 'b' 'c' 'c' 'd' 'd' 'e' 'e' 'f' 'f' 'g' 'g' 'h' 'h']\n",
      "\n",
      "St coeff matr\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [2 1 0]\n",
      " [0 1 1]\n",
      " [1 1 1]]\n",
      "\n",
      "prod names\n",
      "['H', 'L', 'M', 'HL', 'H2L', 'ML', 'HML']\n",
      "['H', 'L', 'M']\n",
      "\n",
      "const\n",
      "[[0.  ]\n",
      " [0.  ]\n",
      " [0.  ]\n",
      " [5.35]\n",
      " [7.34]\n",
      " [7.44]\n",
      " [9.47]]\n",
      "\n",
      "concentrations\n",
      "[[1.911e-02 1.000e-15 1.486e-02]\n",
      " [1.965e-02 4.205e-03 1.451e-02]\n",
      " [1.911e-02 1.000e-15 1.486e-02]\n",
      " [1.965e-02 4.172e-03 1.451e-02]\n",
      " [1.911e-02 1.000e-15 1.486e-02]\n",
      " [1.965e-02 4.173e-03 1.451e-02]\n",
      " [1.911e-02 1.000e-15 1.486e-02]\n",
      " [1.965e-02 4.191e-03 1.451e-02]\n",
      " [2.568e-03 1.000e-15 1.486e-02]\n",
      " [3.495e-03 4.183e-03 1.451e-02]\n",
      " [2.568e-03 1.000e-15 1.486e-02]\n",
      " [3.492e-03 4.171e-03 1.451e-02]\n",
      " [2.568e-03 1.000e-15 1.486e-02]\n",
      " [3.494e-03 4.179e-03 1.451e-02]\n",
      " [2.568e-03 1.000e-15 1.486e-02]\n",
      " [3.495e-03 4.182e-03 1.451e-02]]\n",
      "[]\n",
      "\n",
      "type con\n",
      "0    tot\n",
      "1    tot\n",
      "2    tot\n",
      "3    NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "volumes\n",
      "[1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2]\n",
      "\n",
      "heats\n",
      "[0 -10.0952 0 -10.4137 0 -10.8359 0 -10.7336 0 -9.776 0 -9.9857 0 -9.7711\n",
      " 0 -9.8545]\n",
      "\n",
      "deviations\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "\n",
      "what to find\n",
      "[]\n",
      "[5, 6]\n"
     ]
    }
   ],
   "source": [
    "print('\\nSeries')\n",
    "print(ser_num)\n",
    "print(ser_counts)\n",
    "print(ser_info)\n",
    "\n",
    "print('\\nSt coeff matr')\n",
    "print(st_coeff_matrix)\n",
    "\n",
    "print('\\nprod names')\n",
    "print(prod_names)\n",
    "print(prod_names_con)\n",
    "\n",
    "print('\\nconst')\n",
    "print(lg_k)\n",
    "\n",
    "print('\\nconcentrations')\n",
    "print(con_matrix)\n",
    "\n",
    "print(ign_indices)\n",
    "\n",
    "print('\\ntype con')\n",
    "print(type_con)\n",
    "\n",
    "print('\\nvolumes')\n",
    "print(volumes)\n",
    "\n",
    "print('\\nheats')\n",
    "print(heats)\n",
    "\n",
    "print('\\ndeviations')\n",
    "print(devs)\n",
    "\n",
    "print('\\nwhat to find')\n",
    "print(tar_num)\n",
    "print(dH_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eq conc\n",
      "[[1.91100000e-02 7.93893011e-22 1.48600000e-02 3.39642998e-18\n",
      "  6.34283410e-18 3.24923250e-16 6.65336693e-16]\n",
      " [1.68906909e-02 5.18144295e-09 1.03569385e-02 1.95928735e-05\n",
      "  3.23404122e-05 1.47802615e-03 2.67503539e-03]\n",
      " [1.91100000e-02 7.93893011e-22 1.48600000e-02 3.39642998e-18\n",
      "  6.34283410e-18 3.24923250e-16 6.65336693e-16]\n",
      " [1.69112769e-02 5.12080459e-09 1.03894322e-02 1.93871783e-05\n",
      "  3.20398893e-05 1.46531170e-03 2.65525612e-03]\n",
      " [1.91100000e-02 7.93893011e-22 1.48600000e-02 3.39642998e-18\n",
      "  6.34283410e-18 3.24923250e-16 6.65336693e-16]\n",
      " [1.69106529e-02 5.12263563e-09 1.03884475e-02 1.93933949e-05\n",
      "  3.20489802e-05 1.46569672e-03 2.65585579e-03]\n",
      " [1.91100000e-02 7.93893011e-22 1.48600000e-02 3.39642998e-18\n",
      "  6.34283410e-18 3.24923250e-16 6.65336693e-16]\n",
      " [1.68994223e-02 5.15566353e-09 1.03707234e-02 1.95054702e-05\n",
      "  3.22127857e-05 1.47262991e-03 2.66664668e-03]\n",
      " [2.56800000e-03 1.91344302e-21 1.48600000e-02 1.10004526e-18\n",
      "  2.76061328e-19 7.83130869e-16 2.15491112e-16]\n",
      " [2.58068228e-03 1.14886629e-08 1.03353229e-02 6.63749220e-06\n",
      "  1.67393490e-06 3.27034473e-03 9.04332365e-04]\n",
      " [2.56800000e-03 1.91344302e-21 1.48600000e-02 1.10004526e-18\n",
      "  2.76061328e-19 7.83130869e-16 2.15491112e-16]\n",
      " [2.58039447e-03 1.14427625e-08 1.03472886e-02 6.61023635e-06\n",
      "  1.66687522e-06 3.26104991e-03 9.01661547e-04]\n",
      " [2.56800000e-03 1.91344302e-21 1.48600000e-02 1.10004526e-18\n",
      "  2.76061328e-19 7.83130869e-16 2.15491112e-16]\n",
      " [2.58058639e-03 1.14733511e-08 1.03393115e-02 6.62839966e-06\n",
      "  1.67157970e-06 3.26724650e-03 9.03442057e-04]\n",
      " [2.56800000e-03 1.91344302e-21 1.48600000e-02 1.10004526e-18\n",
      "  2.76061328e-19 7.83130869e-16 2.15491112e-16]\n",
      " [2.58085391e-03 1.14846429e-08 1.03363207e-02 6.63561098e-06\n",
      "  1.67357176e-06 3.26951601e-03 9.04163334e-04]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nEq conc')\n",
    "print(np.array(c_res_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
